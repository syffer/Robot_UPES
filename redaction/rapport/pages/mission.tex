\chapter{The project and my mission}
% cahier des charges

This chapter will introduce the project I was assigned, and the mission I was given.

\section{The project}
% introduction

This new project involves designing an autonomus navigation algorithm for a robot, which will be moving in an unknown environment. 

~~

A robot is a machine that can do the work of a person, automatically or by being controlled (i.e. a computer or a person). In this project, a robot is defined as a mechanical device that has wheels allowing it to move freely in his surrounding.In order to detect and take note of the surroundings, it is also required that the robot is equiped with cameras ans sensors. Those sensors will provide additionnal information, such as depth, height, or spacial position (x, y, z). 
As for now, the \gls{UPES} doesn't have the robot for the moment. 

~~

The robot will have to move in an environment from a position to another. Both of those two positions are known, but the path to take in order to move from one to another is not. Obstacles could be found in this environment (i.e. everything that could be on the way of the robot and block it, like rocks, walls or holes in the ground). 

~~

In general, navigation can be divided into two parts, whether it is performed in a knowned or an unknowned enviromnent. They differ by the knowleadge about the environment the agent possess (the robot) \cite{Russell:2010:AIM} : 
\begin{description}
	\item[Known environment] the agent know the outcome of every action it can take. For a robot, it means that it knows the path to take and all obstacle's positions it can encounter in advance 
	\item[Unknown environment] the agent doesn't know the outcome of every action, and have to learn from his previous actions in order to make good decisions. For a robot, it means that the robot doesn't know the obstacle's position in advance, nor the path to take.
\end{description}
In our case, the robot will explore in an unknown environment, for example it could explore and search into a submarin field, or the planet Mars. 

~~

So as to navigate correctly, a 3-Dimension map will be generated using at least two cameras. The different objects present on this map will be recognized and tagged as to whether they are obstacles or not. A depth map could be used in order to generate the 3D map from two images (i.e. left and right images). Today's 3D map generation technics generally use \gls{DIP} algorithms, but regarding this project, symbolic computing algorithms will be used, as it has been shown in recent research papers that this technic is computing faster than nowadays other algorithms. \Gls{DIP} and symbolic computing are transformations, \gls{image processing} algorithms. % Symbolic computing is a transformation (an image processing) using symbols. 

~~ 

Autonomous navigation means that the robot will have to navigate from it's own, without help and automatically. \gls{AI} will be an essential part of this process. Multiples \gls{AI} algorithms exist, like A$^*$, D$^*$, Swarm Intelligence, \gls{PSO}, Hill Climbing, and Genetic Algorithm. As the robot will navigate in an unknown environment, it is necessary that the robot learn from his previous decisions. In order to do that, a reinforcement learning will be used, which will allow the robot to self-learning through his experiences and a reward policy.  

~~

The \vref{fig:general functionning} shows the general functionning of the robot. This project will be devided into three parts : 
\begin{description}
	\item[3D Map Generation] this part involves processing the images taken by the cameras, reducing the noise, generating the 3D map from (at least) two images and identifying the obstacles (by tagging the 3D map)
	\item[Navigation Part] in this part, the navigation algorithm will be implemented, and will use the tagged 3D map
	\item[\gls{AI} Part] the last part is related to the implementation of a reinforcement learning algorithm through a reward policy
\end{description}


\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{images/diagrams/flowchart_general}	
    \caption{General functionning}
    \label{fig:general functionning}
\end{figure}


~~

In other words, the objective of the reseach is "To design and develop a self-learning algorithm for an autonomous moving system equipped with 3D vision technique" \cite{bib:niharika}.



\section{My mission in this project}
% objectif 

My mission in this project involves a little part of the the 3D map generation, and was separated into two modules, which are related to : 
\begin{enumerate}
	\item basic \gls{image processing} operations
	\item object recognition on 2-dimensional images
\end{enumerate}


\subsubsection{The first module}

The first module involves implementing \gls{image processing} operations on 2-dimensional images. The operations will have to be performed on raster images (i.e. bitmapped images), of type "JPG" and "PNG". Those operations are either morphologic operations, edge detection filters, or noise removal filters. 

~~

The expected edge detection filters are the Sobel filter, the Laplacian filter, and the Canny filter. As for the noise removal filters, the median filter, the weighted average filter and the second \gls{CA} algorithm described in \cite{bib:filter:CA} have to be implemented.


The morphologic operations which are to be implemented are the followings : 
\begin{itemize}
	\item negativity
	\item erosion and expansion
	\item grey scale, transform an image into a grey image
	\item threshold, transform an image into a black and white image 
	\item the \gls{CLAP} \gls{algorithm} described in \cite{bib:filter:EdgeWithCLAP}
\end{itemize}

~~


Moreover, a \gls{GUI} is required in order to see the results of each operations described previously. This \gls{GUI} must allow a user to load, transform and save multiple images. The display of the image \gls{histogram} on the \gls{GUI} is also expected. 


\subsubsection{The second module}

The second module involves the recognition of object on 2-dimensional images. The implementation of the K-Means classification \gls{algorithm} is also required in this module. \Glspl{algorithm} of this module must also be integrated in the \gls{GUI}. Futhermore, the extracted objects must be displayed on the image from which they were extracted (tagged or not). Objects with the same tag must be displayed with the same color, a random color will be used for untagged objects. In order to recognize objetcs on an image the following operations must be done. 

~~

First, objects have to be extracted from the image using edges, chain codes could be used for that part. Each extracted object should also have some features that can be determinated (e.g. the width of the object). 

~~

Then, a database containing existing tagged objects and their features must be created. A dataset containing those existing tagged objects must be found on the internet, and must be stored in the database. 

~~

Finally, an \gls{algorithm} that will tag an object will be implemented. This \gls{algorithm} will return the tag of the nearest tagged object in the database from the object to be tagged by comparing their features. 

 


\section{Constraints and expectations}
% contrainte + attente 

% - contraintes 
% langage laissé à mon choix 

The only given constraint is not to use the programming language Matlab for the image processing part. Exept for Matlab, the programmer is free to use any other programming languages. 

~~

% - attentes 
% réunion régulière, à chaque fois qu'une tâche a été terminé
% documentation 
% rapport 
% code source 

Regular meetings are expected, and at each time a task has been done. At the end of the internship, the following documents must be given in english to the supervisor : 
\begin{itemize}
	\item the commented source code 
	\item the documentation of the source code  
	\item a report on the internship 
\end{itemize}

